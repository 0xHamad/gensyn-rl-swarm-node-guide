<h2 align="center">ğŸš€ Gensyn RL-SWARM Node â€” Ultimate Easy Guide (All Issues Fixed)</h2>

## âš™ï¸ WATCH VIDEO FULL INSTALLTION PROCESS

<p align="center">
  <a href="https://drive.google.com/file/d/10gYpKE8_RqKsbckblI4UH5bSmZANeK8C/view">
    <img src="https://drive.google.com/thumbnail?id=10gYpKE8_RqKsbckblI4UH5bSmZANeK8C&sz=w600-h400" alt="Installation Video" width="600"/>
  </a>
</p>
<p align="center"><i>ğŸ‘† Click to watch full video</i></p>

## âš™ï¸ Hardware Requirements

> ### ğŸ“ Overview  
> Your hardware requirements depend on the **swarm type** and **model size** you choose.  
> - For **low hardware**, use **Qwen 0.5B / 1.5B** + **GSM8K**  
> - For **high hardware**, use **Qwen 7B / 32B / 72B** + **DAPO-Math 17K**  
>  
> Choose according to the details below:

---

> ## ğŸŸ© Small Model (0.5B / 1.5B) â€” GSM8K Dataset  
> For users with mid-level hardware.

### ğŸ“Œ Minimum VPS Requirements
> - **32 GB RAM**  
> - **8 vCPU**  
> - **200 GB Storage**  
> - Best for **default (0.5B) training**

### ğŸ–¥ï¸ CPU Requirements
> - **ARM64** or **x86_64 CPU**  
> - Minimum **32GB RAM**  
> - âš ï¸ **Note:** Running extra applications during training may cause a crash.

### ğŸ® GPU Requirements (CUDA Supported)
> - **RTX 3090**  
> - **RTX 4090**  
> - **A100**  
> - **H100**

---

> ## ğŸŸ¦ Big Model (7B / 32B / 72B) â€” DAPO-Math 17K Dataset  
> For users with powerful hardware.

### ğŸ”¥ Recommended GPUs
> - **NVIDIA A100 (80GB)**  
> - **NVIDIA H100 (80GB)**  

---

## ğŸ–¥ï¸ Node Setup Guide

> ## ğŸ” 1. Open Your VPS  
> Connect to your server:
```bash
ssh username@ip
```
# ğŸš€ RL-SWARM Installation & Setup Guide

A complete step-by-step guide to run RL-SWARM on Linux (VPS/WSL) or Mac.

---

## ğŸ› ï¸ 1. Installation & Setup

Run the following commands step-by-step on your terminal.

1. **Install `sudo`**
```bash
apt update && apt install -y sudo
```
2. **Install other dependencies**
```bash
sudo apt update && sudo apt install -y python3 python3-venv python3-pip curl wget screen git lsof nano unzip iproute2 build-essential gcc g++
```

3. **Create a `screen` session**
```bash
screen -S gensyn
```
4. **Clone official `rl-swarm` repo**
```
git clone https://github.com/gensyn-ai/rl-swarm.git && cd rl-swarm
```
5. **Run the swarm**
```
python3 -m venv .venv
. .venv/bin/activate
./run_rl_swarm.sh
```
![image](https://github.com/user-attachments/assets/40d07439-ffd1-4207-9e51-fabc3fdbb8aa)

- After sometimes, u will see something like this if your running it on Linux system, so here follow the next step
- * Now it will prompt you to login: Follow: [1ï¸âƒ£ How to Login or access http://localhost:3000/ in VPS? ğŸ“¶](https://github.com/0xHamad/gensyn-rl-swarm-node-guide?tab=readme-ov-file#1%EF%B8%8F%E2%83%A3-how-to-login-or-access--httplocalhost3000-in-vps-)

* Now It will promt `Would you like to push models you train in the RL swarm to the Hugging Face Hub? [y/N]` Enter `N`

* Now It will promt `>> Enter the name of the model you want to use in huggingface repo/name format, or press [Enter] to use the default model.`  press `Enter` & get defalut model: 

---â— If U put model manually then it can be cause of terminatedâ—--- So better to use Default:

------>>>If u want to select the model then choose between them:
## 5ï¸âƒ£ Choose customised model's


<pre>

 Gensyn/Qwen2.5-0.5B-Instruct

 Qwen/Qwen3-0.6B

 nvidia/AceInstruct-1.5B

 dnotitia/Smoothie-Qwen3-1.7B

 Gensyn/Qwen2.5-1.5B-Instruct

</pre>

Models (CodeZero):
   - **Qwen/Qwen2.5-Coder-0.5B-Instruct** â€” Solver role (Recommended Choose This)  
   - **Qwen/Qwen2.5-Coder-1.5B-Instruct** â€” Evaluator (frozen)  

Currently, we are running **CodeZero** on the Gensyn Testnet. 

Its Done âœ…

# NEXT


# Detach & Attach from screen

`ctrl` `A` `D` To Detach from screen 

* Attach with previous screen:

```
screen -r gensyn
```



## 1ï¸âƒ£ How to Login or access  http://localhost:3000/ in VPS? ğŸ“¶

* Open a new Terminal and login ur vps 

* Allow Incoming connection on VPS

```
sudo apt install ufw -y
sudo ufw allow 22
sudo ufw allow 3000/tcp
```

* Enable ufw

```
sudo ufw enable
```

* Install cloudflared on the VPS

```
wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb
````

```
sudo dpkg -i cloudflared-linux-amd64.deb
```

* Check version

```
cloudflared --version
```

* Make sure your Node is running on port 3000 in Previous Screen

* Run the tunnel command

```
cloudflared tunnel --url http://localhost:3000
```

* Access the Link from your local machine

    
    ![image](https://github.com/user-attachments/assets/c5bdfec5-123d-4625-8da8-f46269700950)

* Now follow Login!
 
* Done!âœ…

# NEXT 

# 6ï¸âƒ£ **Resolve Bootstraps Error**
![IMG_20251128_093321 (1)](https://github.com/user-attachments/assets/6dc53be6-b88b-4fc6-99a0-4792cacd65f1)

* RUN THIS CMD : (Must you should be in **rl-swarm** directory) â—

```bash
cd ~/rl-swarm
pkill -f python
rm -rf /tmp/hivemind-*
rm -rf /tmp/p2pd-*
source .venv/bin/activate
bash run_rl_swarm.sh
```

> ğŸ‘‰ **Join X for more updates:** https://x.com/Hamad__Alpha  
> ğŸ’¬ **If you have any issue:** Open an issue on this repo or DM me on X:https://x.com/Hamad__Alpha 
>
> **Thank you! Best of luck ğŸš€**




